import pandas as pd
from gws_core import (
    ConfigParams,
    ConfigSpecs,
    InputSpec,
    InputSpecs,
    OutputSpec,
    OutputSpecs,
    ResourceSet,
    StrParam,
    Table,
    Task,
    TaskInputs,
    TaskOutputs,
    task_decorator,
)


@task_decorator(
    "ResourceSetToDataTable",
    human_name="ResourceSet to Data Table",
    short_description="Converts a ResourceSet from Quality Check into a Table with time column and one column per batch/sample pair",
)
class ResourceSetToDataTable(Task):
    """
    [Generated by Task Expert Agent]

    # ResourceSet to Data Table

    Transforms a **ResourceSet** (output from Quality Check tasks) into a **Table** organized by batch/sample pairs.

    ## Description

    This task extracts data from a ResourceSet containing multiple Table resources (one per batch/sample).
    It creates a unified table where:
    - The first column is the **index column** (e.g., temperature, time)
    - Each subsequent column represents a **batch/sample pair** (named "Batch_Sample")
    - Column values are taken from the selected **data column**

    ## Inputs

    - **resource_set**: ResourceSet containing Table resources with batch/sample tags

    ## Configuration

    - **index_column**: Column name to use as the table index (e.g., "Temp", "Time")
    - **data_column**: Column name containing the data to extract (e.g., "Biomasse", "pH")

    ## Output

    - **data_table**: Table with index column and one column per batch/sample pair

    ## Usage Example

    Given a ResourceSet with 3 tables (Batch1_Sample1, Batch1_Sample2, Batch2_Sample1),
    each containing columns [Time, Biomasse, pH], selecting:
    - index_column = "Time"
    - data_column = "Biomasse"

    Will produce a table:
    ```
    Time | Batch1_Sample1 | Batch1_Sample2 | Batch2_Sample1
    -----|----------------|----------------|---------------
    0    | 0.1            | 0.12           | 0.11
    24   | 0.5            | 0.48           | 0.52
    48   | 1.2            | 1.15           | 1.25
    ```

    ## Notes

    - Batch and sample information is extracted from resource tags
    - Missing values (NaN) in the index column are automatically removed
    - Tables are merged using outer join to preserve all time points
    - Final table is sorted by the index column
    """

    # Tag constants for batch and sample identification
    TAG_BATCH = "fermentor_batch"
    TAG_SAMPLE = "fermentor_sample"

    input_specs = InputSpecs(
        {
            "resource_set": InputSpec(
                ResourceSet,
                human_name="Resource Set",
                short_description="ResourceSet containing Table resources from Quality Check",
            )
        }
    )

    output_specs = OutputSpecs(
        {
            "data_table": OutputSpec(
                Table,
                human_name="Data Table",
                short_description="Table with index column and one column per batch/sample pair",
            )
        }
    )

    config_specs = ConfigSpecs(
        {
            "index_column": StrParam(
                human_name="Index Column",
                short_description="Column to use as index (e.g., 'Temp', 'Time')",
                default_value="Temp",
            ),
            "data_column": StrParam(
                human_name="Data Column",
                short_description="Column containing data to extract (e.g., 'Biomasse', 'pH')",
                default_value="Biomasse",
            ),
        }
    )

    def run(self, params: ConfigParams, inputs: TaskInputs) -> TaskOutputs:
        """
        Build a DataFrame for a specific data column from the ResourceSet.
        The dataframe will contain the index column and data columns.
        One data column per couple batch/sample, named Batch_Sample.
        """
        resource_set: ResourceSet = inputs["resource_set"]
        index_column: str = params.get_value("index_column")
        data_column: str = params.get_value("data_column")

        self.log_info_message(
            f"Converting ResourceSet to Table with index='{index_column}' and data='{data_column}'"
        )
        self.update_progress_value(10, "Extracting resources from ResourceSet")

        try:
            resources = resource_set.get_resources()
            combined_data = pd.DataFrame()
            processed_count = 0
            total_resources = len(resources)

            self.log_info_message(f"Found {total_resources} resources in ResourceSet")

            for resource_name, resource in resources.items():
                if isinstance(resource, Table):
                    df = resource.get_data()

                    # Check if required columns exist
                    if index_column not in df.columns:
                        self.log_warning_message(
                            f"Resource '{resource_name}': index column '{index_column}' not found. Skipping."
                        )
                        continue

                    if data_column not in df.columns:
                        self.log_warning_message(
                            f"Resource '{resource_name}': data column '{data_column}' not found. Skipping."
                        )
                        continue

                    # Extract batch and sample from tags
                    batch = ""
                    sample = ""

                    if hasattr(resource, "tags") and resource.tags:
                        for tag in resource.tags.get_tags():
                            if tag.key == self.TAG_BATCH:
                                batch = tag.value
                            elif tag.key == self.TAG_SAMPLE:
                                sample = tag.value

                    # Create column label
                    column_label = f"{batch}_{sample}" if batch and sample else resource_name
                    self.log_info_message(
                        f"Processing resource '{resource_name}' as column '{column_label}'"
                    )

                    # Create a copy of the relevant columns
                    temp_df = df[[index_column, data_column]].copy()
                    temp_df = temp_df.rename(columns={data_column: column_label})

                    # Remove any NaN values in the index column
                    original_len = len(temp_df)
                    temp_df = temp_df.dropna(subset=[index_column])
                    dropped_count = original_len - len(temp_df)

                    if dropped_count > 0:
                        self.log_info_message(
                            f"Removed {dropped_count} rows with NaN in '{index_column}' from '{column_label}'"
                        )

                    # Merge with combined data
                    if combined_data.empty:
                        combined_data = temp_df
                    else:
                        combined_data = pd.merge(
                            combined_data, temp_df, on=index_column, how="outer"
                        )

                    processed_count += 1
                    progress = 10 + int((processed_count / total_resources) * 70)
                    self.update_progress_value(
                        progress, f"Processed {processed_count}/{total_resources} resources"
                    )

            # Validate result
            if combined_data.empty:
                self.log_error_message("No valid data could be extracted from ResourceSet")
                raise ValueError(
                    f"Failed to build table: no resources contained both '{index_column}' and '{data_column}' columns"
                )

            # Sort by index column
            self.update_progress_value(85, "Sorting and finalizing table")
            if index_column in combined_data.columns:
                combined_data = combined_data.sort_values(by=index_column).reset_index(drop=True)

            # Create output table
            self.update_progress_value(95, "Creating output Table resource")
            output_table = Table(data=combined_data)

            # Log summary
            num_rows = len(combined_data)
            num_cols = len(combined_data.columns) - 1  # Exclude index column
            self.log_success_message(
                f"Successfully created table with {num_rows} rows and {num_cols} batch/sample columns"
            )

            self.update_progress_value(100, "Complete")
            return {"data_table": output_table}

        except Exception as e:
            self.log_error_message(f"Error during conversion: {str(e)}")
            raise
