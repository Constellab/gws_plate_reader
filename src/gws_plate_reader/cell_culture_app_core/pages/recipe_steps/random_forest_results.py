"""
Random Forest Regression Results Display for Cell Culture Dashboard
Displays results from Random Forest regression analysis
"""
import streamlit as st
from gws_core import Scenario, ScenarioProxy, ScenarioStatus
from gws_plate_reader.cell_culture_app_core.cell_culture_state import CellCultureState
from gws_plate_reader.cell_culture_app_core.cell_culture_recipe import CellCultureRecipe


def render_random_forest_results(recipe: CellCultureRecipe, cell_culture_state: CellCultureState,
                                 rf_scenario: Scenario) -> None:
    """
    Render the Random Forest Regression analysis results

    :param recipe: The Recipe instance
    :param cell_culture_state: The cell culture state
    :param rf_scenario: The Random Forest regression scenario to display results for
    """
    st.markdown(f"### üå≤ R√©sultats Random Forest Regression")
    st.markdown(f"**Analyse** : {rf_scenario.title}")
    st.markdown(f"**Statut** : {rf_scenario.status.name}")

    if rf_scenario.status != ScenarioStatus.SUCCESS:
        if rf_scenario.status == ScenarioStatus.ERROR:
            st.error("‚ùå L'analyse a √©chou√©")
        elif rf_scenario.status.is_running():
            st.info("‚è≥ L'analyse est en cours d'ex√©cution...")
        else:
            st.warning(f"‚ö†Ô∏è Statut de l'analyse : {rf_scenario.status.name}")
        return

    try:
        # Get the scenario proxy to access outputs
        scenario_proxy = ScenarioProxy.from_existing_scenario(rf_scenario.id)
        protocol_proxy = scenario_proxy.get_protocol()

        # Get all output resources
        summary_table_model = protocol_proxy.get_output_resource_model('summary_table')
        vip_table_model = protocol_proxy.get_output_resource_model('vip_table')
        vip_plot_model = protocol_proxy.get_output_resource_model('vip_plot')
        plot_estimators_model = protocol_proxy.get_output_resource_model('plot_estimators')
        plot_train_model = protocol_proxy.get_output_resource_model('plot_train_set')
        plot_test_model = protocol_proxy.get_output_resource_model('plot_test_set')

        # Display results in tabs
        tabs = st.tabs([
            "üìà Performance",
            "üéØ Importance des variables",
            "üî¨ Pr√©dictions Train",
            "‚úÖ Pr√©dictions Test"
        ])

        # Tab 1: Performance metrics and estimators plot
        with tabs[0]:
            st.markdown("#### üìà Performance du mod√®le")

            # Display CV plot
            if plot_estimators_model:
                st.markdown("**Optimisation des hyperparam√®tres (Validation crois√©e)**")
                plot_estimators = plot_estimators_model.get_resource()
                st.plotly_chart(plot_estimators.figure, use_container_width=True)
                st.info(
                    "üí° Le graphique montre la performance (score) pour diff√©rentes combinaisons d'hyperparam√®tres (nombre d'arbres, profondeur)")

            st.markdown("---")

            # Display summary table
            if summary_table_model:
                st.markdown("**M√©triques de performance**")
                summary_table = summary_table_model.get_resource()
                summary_df = summary_table.get_data()

                st.dataframe(summary_df, use_container_width=True)

                # Download button
                csv = summary_df.to_csv(index=True)
                st.download_button(
                    label="üì• T√©l√©charger les m√©triques (CSV)",
                    data=csv,
                    file_name=f"rf_metrics_{rf_scenario.id[:8]}.csv",
                    mime="text/csv"
                )

                st.markdown("""
**Interpr√©tation** :
- **R¬≤ (Train)** : Qualit√© d'ajustement sur les donn√©es d'entra√Ænement (0-1, plus proche de 1 = meilleur)
- **R¬≤ (Test)** : Qualit√© de pr√©diction sur les donn√©es de test (indicateur de g√©n√©ralisation)
- **RMSE (Train/Test)** : Erreur quadratique moyenne (plus faible = meilleur)
- Si R¬≤ Test << R¬≤ Train : possible sur-apprentissage
""")

        # Tab 2: Feature importances
        with tabs[1]:
            st.markdown("#### üéØ Importance des variables (Feature Importances)")

            # Display importance plot
            if vip_plot_model:
                st.markdown("**Top 10 variables les plus importantes**")
                vip_plot = vip_plot_model.get_resource()
                st.plotly_chart(vip_plot.figure, use_container_width=True)

                st.info("üí° Les barres plus longues indiquent les variables qui contribuent le plus aux pr√©dictions du mod√®le")

            st.markdown("---")

            # Display importance table
            if vip_table_model:
                st.markdown("**Table des importances (Top variables)**")
                vip_table = vip_table_model.get_resource()
                vip_df = vip_table.get_data()

                st.dataframe(vip_df, use_container_width=True)

                # Download button
                csv = vip_df.to_csv(index=True)
                st.download_button(
                    label="üì• T√©l√©charger les importances (CSV)",
                    data=csv,
                    file_name=f"rf_importances_{rf_scenario.id[:8]}.csv",
                    mime="text/csv"
                )

                st.markdown("""
**Interpr√©tation Feature Importance** :
- Les scores sont normalis√©s (somme = 1)
- Plus le score est √©lev√©, plus la variable est importante
- Indique quelles variables (nutriments, conditions) influencent le plus les r√©sultats
- Contrairement au VIP de PLS, pas de seuil strict, mais comparer les valeurs relatives
""")

        # Tab 3: Train predictions
        with tabs[2]:
            st.markdown("#### üî¨ Pr√©dictions vs Observations (Train Set)")

            if plot_train_model:
                plot_train = plot_train_model.get_resource()
                st.plotly_chart(plot_train.figure, use_container_width=True)

                st.markdown("""
**Interpr√©tation** :
- Les points proches de la diagonale indiquent de bonnes pr√©dictions
- Dispersion autour de la diagonale = erreur de pr√©diction
- Random Forest peut sur-apprendre sur le train set (normal si R¬≤ Train tr√®s √©lev√©)
""")

        # Tab 4: Test predictions
        with tabs[3]:
            st.markdown("#### ‚úÖ Pr√©dictions vs Observations (Test Set)")

            if plot_test_model:
                plot_test = plot_test_model.get_resource()
                st.plotly_chart(plot_test.figure, use_container_width=True)

                st.markdown("""
**Interpr√©tation** :
- Performance sur donn√©es non vues pendant l'entra√Ænement
- √âvalue la capacit√© de g√©n√©ralisation du mod√®le
- Si performances train >> test : sur-apprentissage (r√©duire profondeur des arbres)
- Points s'√©cartant fortement de la diagonale = outliers ou cas particuliers
""")

    except Exception as e:
        st.error(f"Erreur lors de l'affichage des r√©sultats : {str(e)}")
        import traceback
        st.code(traceback.format_exc())

    # Additional information section
    with st.expander("‚ÑπÔ∏è Guide d'interpr√©tation Random Forest"):
        st.markdown("""
### Comment interpr√©ter les r√©sultats Random Forest ?

#### 1. Performance du mod√®le (Tab 1)

**Graphique d'optimisation des hyperparam√®tres** :
- Montre le score de validation crois√©e pour diff√©rentes configurations
- **n_estimators** : nombre d'arbres dans la for√™t
- **max_depth** : profondeur maximale de chaque arbre
- Le mod√®le s√©lectionne automatiquement la meilleure combinaison

**M√©triques** :
- **R¬≤ proche de 1** : Excellent mod√®le
- **R¬≤ autour de 0.7-0.9** : Bon mod√®le
- **R¬≤ < 0.5** : Mod√®le faible, revoir les variables ou les donn√©es
- **RMSE** : Erreur en unit√©s de la variable cible (plus faible = meilleur)

**Diff√©rence Random Forest vs PLS** :
- Random Forest peut capturer des relations non-lin√©aires
- G√©n√©ralement meilleur R¬≤ Train (peut sur-apprendre)
- Moins sensible √† la multicolin√©arit√©

#### 2. Importance des variables (Tab 2)

**Feature Importances** :
- Bas√©es sur la r√©duction de l'impuret√© (Gini importance)
- Identifie les variables les plus utilis√©es pour les d√©cisions
- Scores normalis√©s : somme = 1

**Applications** :
- Identifier les facteurs critiques pour la variable cible
- Simplifier les exp√©riences futures en se concentrant sur les variables importantes
- Compr√©hension des m√©canismes biologiques

**Diff√©rence avec VIP (PLS)** :
- Pas de seuil universel comme VIP > 1
- Comparer les importances relatives entre variables
- Les importances faibles (<0.01) peuvent souvent √™tre ignor√©es

#### 3. Pr√©dictions (Tabs 3 et 4)

**Train Set** :
- Random Forest tend √† avoir un tr√®s bon R¬≤ Train (proche de 1)
- Normal car le mod√®le peut "m√©moriser" les donn√©es
- Ce n'est pas n√©cessairement du sur-apprentissage si Test est bon aussi

**Test Set** :
- **CRITIQUE** : vrai indicateur de performance
- Si R¬≤ Test > 0.7 : bon mod√®le g√©n√©ralisable
- Si R¬≤ Test < 0.5 : mod√®le faible ou donn√©es insuffisantes
- √âcart Train-Test < 0.2 : mod√®le √©quilibr√©

#### 4. Utilisation pratique

**Pour optimiser un proc√©d√©** :
1. Identifier les top 5-10 variables importantes
2. Analyser leur distribution dans les meilleurs r√©sultats
3. Tester de nouvelles conditions en variant ces facteurs cl√©s

**Pour pr√©dire des performances** :
1. V√©rifier R¬≤ Test > 0.7
2. S'assurer que les nouvelles conditions sont dans le range des donn√©es Train
3. Random Forest pr√©dit mieux que PLS si relations non-lin√©aires

**Comparer avec PLS** :
- Si RF >> PLS : relations non-lin√©aires importantes
- Si RF ‚âà PLS : relations plut√¥t lin√©aires, PLS plus interpr√©table
- Utiliser les deux pour confirmer les variables importantes

#### 5. Limites et pr√©cautions

**Sur-apprentissage** :
- Si R¬≤ Train = 1 et R¬≤ Test < 0.6 : sur-apprentissage s√©v√®re
- Solution : augmenter test_size, limiter max_depth

**Extrapolation** :
- Random Forest ne peut pas extrapoler hors des donn√©es d'entra√Ænement
- Les pr√©dictions seront plateaux aux limites des donn√©es

**Interpr√©tabilit√©** :
- Moins interpr√©table que PLS (bo√Æte noire)
- Importances donnent une id√©e, mais pas d'√©quation simple
- Pour comprendre les m√©canismes : privil√©gier PLS ou mod√®les lin√©aires
""")
