"""
Random Forest Regression Results Display for Cell Culture Dashboard
Displays results from Random Forest regression analysis
"""
import streamlit as st
from gws_core import Scenario, ScenarioProxy, ScenarioStatus
from gws_plate_reader.cell_culture_app_core.cell_culture_state import CellCultureState
from gws_plate_reader.cell_culture_app_core.cell_culture_recipe import CellCultureRecipe


def render_random_forest_results(recipe: CellCultureRecipe, cell_culture_state: CellCultureState,
                                 rf_scenario: Scenario) -> None:
    """
    Render the Random Forest Regression analysis results

    :param recipe: The Recipe instance
    :param cell_culture_state: The cell culture state
    :param rf_scenario: The Random Forest regression scenario to display results for
    """
    st.markdown(f"### ğŸŒ² RÃ©sultats Random Forest Regression")
    st.markdown(f"**Analyse** : {rf_scenario.title}")
    st.markdown(f"**Statut** : {rf_scenario.status.name}")

    if rf_scenario.status != ScenarioStatus.SUCCESS:
        if rf_scenario.status == ScenarioStatus.ERROR:
            st.error("âŒ L'analyse a Ã©chouÃ©")
        elif rf_scenario.status.is_running():
            st.info("â³ L'analyse est en cours d'exÃ©cution...")
        else:
            st.warning(f"âš ï¸ Statut de l'analyse : {rf_scenario.status.name}")
        return

    try:
        # Get the scenario proxy to access outputs
        scenario_proxy = ScenarioProxy.from_existing_scenario(rf_scenario.id)
        protocol_proxy = scenario_proxy.get_protocol()

        # Get all output resources
        summary_table_model = protocol_proxy.get_output_resource_model('summary_table')
        vip_table_model = protocol_proxy.get_output_resource_model('vip_table')
        plot_estimators_model = protocol_proxy.get_output_resource_model('plot_estimators')
        vip_plot_model = protocol_proxy.get_output_resource_model('vip_plot')
        plot_train_model = protocol_proxy.get_output_resource_model('plot_train_set')
        plot_test_model = protocol_proxy.get_output_resource_model('plot_test_set')
        merged_table_model = protocol_proxy.get_output_resource_model('merged_table')

        # Display results in tabs
        tabs = st.tabs([
            "ğŸ“ˆ Performance",
            "ğŸ¯ Importance des variables",
            "ğŸ”¬ PrÃ©dictions Train",
            "âœ… PrÃ©dictions Test",
            "ğŸ“Š Table fusionnÃ©e"
        ])

        # Tab 1: Performance metrics and estimators plot
        with tabs[0]:
            st.markdown("#### ğŸ“ˆ Performance du modÃ¨le")

            # Display estimators plot
            if plot_estimators_model:
                st.markdown("**Optimisation des hyperparamÃ¨tres (Validation croisÃ©e)**")
                plot_estimators = plot_estimators_model.get_resource()
                st.plotly_chart(plot_estimators.figure, use_container_width=True)
                st.info(
                    "ğŸ’¡ Le graphique montre la performance (score) pour diffÃ©rentes combinaisons d'hyperparamÃ¨tres (nombre d'arbres, profondeur)")

            st.markdown("---")

            # Display summary table
            if summary_table_model:
                st.markdown("**MÃ©triques de performance**")
                summary_table = summary_table_model.get_resource()
                summary_df = summary_table.get_data()

                st.dataframe(summary_df, use_container_width=True)

                # Download button
                csv = summary_df.to_csv(index=True)
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger les mÃ©triques (CSV)",
                    data=csv,
                    file_name=f"rf_metrics_{rf_scenario.id[:8]}.csv",
                    mime="text/csv"
                )

                st.markdown("""
**InterprÃ©tation** :
- **RÂ² (Train)** : QualitÃ© d'ajustement sur les donnÃ©es d'entraÃ®nement (0-1, plus proche de 1 = meilleur)
- **RÂ² (Test)** : QualitÃ© de prÃ©diction sur les donnÃ©es de test (indicateur de gÃ©nÃ©ralisation)
- **RMSE (Train/Test)** : Erreur quadratique moyenne (plus faible = meilleur)
- Si RÂ² Test << RÂ² Train : possible sur-apprentissage
""")

        # Tab 2: Feature importances
        with tabs[1]:
            st.markdown("#### ğŸ¯ Importance des variables (Feature Importances)")

            # Display importance plot
            if vip_plot_model:
                st.markdown("**Top 10 variables les plus importantes**")
                vip_plot = vip_plot_model.get_resource()
                st.plotly_chart(vip_plot.figure, use_container_width=True)

                st.info("ğŸ’¡ Les barres plus longues indiquent les variables qui contribuent le plus aux prÃ©dictions du modÃ¨le")

            st.markdown("---")

            # Display importance table
            if vip_table_model:
                st.markdown("**Table des importances (Top variables)**")
                vip_table = vip_table_model.get_resource()
                vip_df = vip_table.get_data()

                st.dataframe(vip_df, use_container_width=True)

                # Download button
                csv = vip_df.to_csv(index=True)
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger les importances (CSV)",
                    data=csv,
                    file_name=f"rf_importances_{rf_scenario.id[:8]}.csv",
                    mime="text/csv"
                )

                st.markdown("""
**InterprÃ©tation Feature Importance** :
- Les scores sont normalisÃ©s (somme = 1)
- Plus le score est Ã©levÃ©, plus la variable est importante
- Indique quelles variables (nutriments, conditions) influencent le plus les rÃ©sultats
- Contrairement au VIP de PLS, pas de seuil strict, mais comparer les valeurs relatives
""")

        # Tab 3: Train predictions
        with tabs[2]:
            st.markdown("#### ğŸ”¬ PrÃ©dictions vs Observations (Train Set)")

            if plot_train_model:
                plot_train = plot_train_model.get_resource()
                st.plotly_chart(plot_train.figure, use_container_width=True)

                st.markdown("""
**InterprÃ©tation** :
- Les points proches de la diagonale indiquent de bonnes prÃ©dictions
- Dispersion autour de la diagonale = erreur de prÃ©diction
- Random Forest peut sur-apprendre sur le train set (normal si RÂ² Train trÃ¨s Ã©levÃ©)
""")

        # Tab 4: Test predictions
        with tabs[3]:
            st.markdown("#### âœ… PrÃ©dictions vs Observations (Test Set)")

            if plot_test_model:
                plot_test = plot_test_model.get_resource()
                st.plotly_chart(plot_test.figure, use_container_width=True)

                st.markdown("""
**InterprÃ©tation** :
- Performance sur donnÃ©es non vues pendant l'entraÃ®nement
- Ã‰value la capacitÃ© de gÃ©nÃ©ralisation du modÃ¨le
- Si performances train >> test : sur-apprentissage (rÃ©duire profondeur des arbres)
- Points s'Ã©cartant fortement de la diagonale = outliers ou cas particuliers
""")

        # Tab 5: Merged table
        with tabs[4]:
            st.markdown("#### ğŸ“Š Table fusionnÃ©e (MÃ©tadonnÃ©es + Features)")

            if merged_table_model:
                merged_table = merged_table_model.get_resource()
                merged_df = merged_table.get_data()

                st.markdown(f"**Dimensions** : {merged_df.shape[0]} lignes Ã— {merged_df.shape[1]} colonnes")

                # Display table
                st.dataframe(merged_df, use_container_width=True, height=400)

                # Download button
                csv = merged_df.to_csv(index=True)
                st.download_button(
                    label="ğŸ“¥ TÃ©lÃ©charger la table fusionnÃ©e (CSV)",
                    data=csv,
                    file_name=f"rf_merged_table_{rf_scenario.id[:8]}.csv",
                    mime="text/csv"
                )

                st.info("ğŸ’¡ Cette table contient les donnÃ©es brutes utilisÃ©es pour l'analyse Random Forest (mÃ©tadonnÃ©es + features)")

    except Exception as e:
        st.error(f"Erreur lors de l'affichage des rÃ©sultats : {str(e)}")
        import traceback
        st.code(traceback.format_exc())

    # Additional information section
    with st.expander("â„¹ï¸ Guide d'interprÃ©tation Random Forest"):
        st.markdown("""
### Comment interprÃ©ter les rÃ©sultats Random Forest ?

#### 1. Performance du modÃ¨le (Tab 1)

**Graphique d'optimisation des hyperparamÃ¨tres** :
- Montre le score de validation croisÃ©e pour diffÃ©rentes configurations
- **n_estimators** : nombre d'arbres dans la forÃªt
- **max_depth** : profondeur maximale de chaque arbre
- Le modÃ¨le sÃ©lectionne automatiquement la meilleure combinaison

**MÃ©triques** :
- **RÂ² proche de 1** : Excellent modÃ¨le
- **RÂ² autour de 0.7-0.9** : Bon modÃ¨le
- **RÂ² < 0.5** : ModÃ¨le faible, revoir les variables ou les donnÃ©es
- **RMSE** : Erreur en unitÃ©s de la variable cible (plus faible = meilleur)

**DiffÃ©rence Random Forest vs PLS** :
- Random Forest peut capturer des relations non-linÃ©aires
- GÃ©nÃ©ralement meilleur RÂ² Train (peut sur-apprendre)
- Moins sensible Ã  la multicolinÃ©aritÃ©

#### 2. Importance des variables (Tab 2)

**Feature Importances** :
- BasÃ©es sur la rÃ©duction de l'impuretÃ© (Gini importance)
- Identifie les variables les plus utilisÃ©es pour les dÃ©cisions
- Scores normalisÃ©s : somme = 1

**Applications** :
- Identifier les facteurs critiques pour la variable cible
- Simplifier les expÃ©riences futures en se concentrant sur les variables importantes
- ComprÃ©hension des mÃ©canismes biologiques

**DiffÃ©rence avec VIP (PLS)** :
- Pas de seuil universel comme VIP > 1
- Comparer les importances relatives entre variables
- Les importances faibles (<0.01) peuvent souvent Ãªtre ignorÃ©es

#### 3. PrÃ©dictions (Tabs 3 et 4)

**Train Set** :
- Random Forest tend Ã  avoir un trÃ¨s bon RÂ² Train (proche de 1)
- Normal car le modÃ¨le peut "mÃ©moriser" les donnÃ©es
- Ce n'est pas nÃ©cessairement du sur-apprentissage si Test est bon aussi

**Test Set** :
- **CRITIQUE** : vrai indicateur de performance
- Si RÂ² Test > 0.7 : bon modÃ¨le gÃ©nÃ©ralisable
- Si RÂ² Test < 0.5 : modÃ¨le faible ou donnÃ©es insuffisantes
- Ã‰cart Train-Test < 0.2 : modÃ¨le Ã©quilibrÃ©

#### 4. Utilisation pratique

**Pour optimiser un procÃ©dÃ©** :
1. Identifier les top 5-10 variables importantes
2. Analyser leur distribution dans les meilleurs rÃ©sultats
3. Tester de nouvelles conditions en variant ces facteurs clÃ©s

**Pour prÃ©dire des performances** :
1. VÃ©rifier RÂ² Test > 0.7
2. S'assurer que les nouvelles conditions sont dans le range des donnÃ©es Train
3. Random Forest prÃ©dit mieux que PLS si relations non-linÃ©aires

**Comparer avec PLS** :
- Si RF >> PLS : relations non-linÃ©aires importantes
- Si RF â‰ˆ PLS : relations plutÃ´t linÃ©aires, PLS plus interprÃ©table
- Utiliser les deux pour confirmer les variables importantes

#### 5. Limites et prÃ©cautions

**Sur-apprentissage** :
- Si RÂ² Train = 1 et RÂ² Test < 0.6 : sur-apprentissage sÃ©vÃ¨re
- Solution : augmenter test_size, limiter max_depth

**Extrapolation** :
- Random Forest ne peut pas extrapoler hors des donnÃ©es d'entraÃ®nement
- Les prÃ©dictions seront plateaux aux limites des donnÃ©es

**InterprÃ©tabilitÃ©** :
- Moins interprÃ©table que PLS (boÃ®te noire)
- Importances donnent une idÃ©e, mais pas d'Ã©quation simple
- Pour comprendre les mÃ©canismes : privilÃ©gier PLS ou modÃ¨les linÃ©aires
""")
